"""Context manager for conversation continuity and memory handling."""

import re
from datetime import datetime
from typing import Any, Dict, List, Optional


class ConversationContext:
    """Manages conversation context and continuity."""
    
    def __init__(self, identity_config: Dict[str, Any]):
        """Initialize the context manager with identity configuration."""
        self.identity_config = identity_config
        self.conversation_config = identity_config.get("conversation_management", {})
        self.routing_config = identity_config.get("routing_configuration", {})
        
        # Conversation state
        self.user_name: Optional[str] = None
        self.current_topic: Optional[str] = None
        self.interaction_count: int = 0
        self.last_user_language: str = "en"
        
        # Rolling conversation window
        self.context_window_size = self.conversation_config.get("context_window_size", 3)
        self.conversation_history: List[Dict[str, Any]] = []
        
        # Topic tracking
        self.topic_stack: List[str] = []
        self.entity_mentions: Dict[str, int] = {}  # Track frequently mentioned entities
        
    def update_from_input(self, user_input: str) -> None:
        """Update context based on new user input."""
        self.interaction_count += 1
        
        # Detect language
        self.last_user_language = self._detect_language(user_input)
        
        # Extract and update user name if mentioned
        self._extract_user_name(user_input)
        
        # Track topics and entities
        self._update_topic_tracking(user_input)
        
        # Add to conversation history
        self.conversation_history.append({
            "type": "user_input",
            "content": user_input,
            "timestamp": datetime.now().isoformat(),
            "language": self.last_user_language,
            "detected_entities": self._extract_entities(user_input)
        })
        
        # Trim history to context window
        if len(self.conversation_history) > self.context_window_size * 2:  # *2 for user+assistant pairs
            self.conversation_history = self.conversation_history[-self.context_window_size * 2:]
    
    def add_response(self, response: str, metadata: Optional[Dict[str, Any]] = None) -> None:
        """Add assistant response to context."""
        self.conversation_history.append({
            "type": "assistant_response",
            "content": response,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        })
        
        # Extract topics from our own response for better tracking
        self._update_topic_tracking(response, is_assistant=True)
    
    def build_context_prompt(self, user_input: str) -> str:
        """Build a context-aware prompt for the current input."""
        # Check if this is a reference question first
        reference_info = self._detect_references(user_input)
        
        if reference_info:
            # This is a continuation/reference question
            return self._build_reference_prompt(user_input, reference_info)
        
        # Check if user is asking about themselves
        if self._is_self_reference_question(user_input):
            return self._build_self_reference_prompt(user_input)
        
        # Check if this is a simple greeting that shouldn't have context
        if self._is_simple_greeting(user_input):
            return user_input
        
        # Build context-enhanced prompt
        context_parts = []
        
        # Add user identity if known and relevant
        if self.user_name:
            if self.last_user_language == "ru":
                context_parts.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {self.user_name}.")
            else:
                context_parts.append(f"User's name is {self.user_name}.")
        
        # Add relevant conversation context (especially important for external->local transitions)
        conversation_context = self._build_conversation_context()
        if conversation_context:
            context_parts.append(conversation_context)
        
        # Build final prompt
        if context_parts:
            context_str = " ".join(context_parts)
            if self.last_user_language == "ru":
                return f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_str}\n\n–í–æ–ø—Ä–æ—Å: {user_input}"
            else:
                return f"Context: {context_str}\n\nQuestion: {user_input}"
        
        return user_input
    
    def _detect_language(self, text: str) -> str:
        """Detect the language of the input text."""
        # Simple Cyrillic detection
        cyrillic_chars = sum(1 for char in text if '\u0400' <= char <= '\u04FF')
        total_chars = len([char for char in text if char.isalpha()])
        
        if total_chars > 0 and cyrillic_chars / total_chars > 0.3:
            return "ru"
        return "en"
    
    def _extract_user_name(self, user_input: str) -> None:
        """Extract user name from input using configured patterns."""
        patterns = self.conversation_config.get("name_extraction", {}).get("patterns", [])
        
        # Common directional/non-name words that should never be names
        non_name_words = {
            "–≤–≤–µ—Ä—Ö", "–≤–Ω–∏–∑", "–≤–ª–µ–≤–æ", "–≤–ø—Ä–∞–≤–æ", "–Ω–∞–∑–∞–¥", "–≤–ø–µ—Ä–µ–¥", "—Ç—É–¥–∞", "—Å—é–¥–∞", "–æ–±—Ä–∞—Ç–Ω–æ",
            "up", "down", "left", "right", "back", "forward", "there", "here",
            "—á—Ç–æ", "–∫–∞–∫", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", "–∫—Ç–æ", "–∫—É–¥–∞", "–æ—Ç–∫—É–¥–∞",
            "who", "what", "where", "when", "why", "how", "which", "whom",
            "—Ç–∞–∫–æ–µ", "–ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "–æ–±—Ä–∞–∑—É–µ—Ç—Å—è", "–ø–æ–¥–Ω–∏–º–∞–µ—Ç—Å—è", "–æ–ø—É—Å–∫–∞–µ—Ç—Å—è"
        }
        
        for pattern in patterns:
            match = re.search(pattern, user_input.lower())
            if match:
                extracted_name = match.group(1).strip().capitalize()
                # Only update if it's a reasonable name (not a common word or direction)
                if (len(extracted_name) > 1 and 
                    extracted_name.lower() not in non_name_words and
                    # Additional check: don't extract if the current user already has a valid name
                    (not self.user_name or self.user_name.lower() in {"unknown", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"})):
                    self.user_name = extracted_name
                    print(f"üë§ User name extracted: {self.user_name}")
                    break
    
    def _update_topic_tracking(self, text: str, is_assistant: bool = False) -> None:
        """Update topic tracking from text."""
        # Extract important words/entities
        entities = self._extract_entities(text)
        
        # Filter out user names from topic tracking to avoid confusion
        filtered_entities = []
        for entity in entities:
            # Skip if this entity is the user's name
            if self.user_name and entity.lower() == self.user_name.lower():
                continue
            filtered_entities.append(entity)
        
        # Update entity frequency
        for entity in filtered_entities:
            self.entity_mentions[entity] = self.entity_mentions.get(entity, 0) + 1
        
        # Update current topic (most frequently mentioned entity recently)
        if filtered_entities:
            # Weight recent entities more heavily
            recent_weight = 2 if not is_assistant else 1
            for entity in filtered_entities:
                self.entity_mentions[entity] = self.entity_mentions.get(entity, 0) + recent_weight
            
            # Set current topic to most frequent recent entity, but prefer scientific nouns over verbs
            sorted_entities = sorted(self.entity_mentions.items(), key=lambda x: x[1], reverse=True)
            
            # Define scientific nouns that should be preferred as topics
            scientific_nouns = {"–ª—ë–¥", "–ª–µ–¥", "ice", "–ø–∞—Ä", "vapor", "–≤–æ–¥–∞", "water", "–≥–∞–∑", "gas", 
                              "–º–æ–ª–µ–∫—É–ª–∞", "–∞—Ç–æ–º", "—ç–Ω–µ—Ä–≥–∏—è", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "–¥–∞–≤–ª–µ–Ω–∏–µ", "—Ö–∏–º–∏—è", "—Ñ–∏–∑–∏–∫–∞"}
            
            # Generic verbs that should not be topics
            generic_verbs = {"–æ–±—Ä–∞–∑—É–µ—Ç—Å—è", "–ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "—Å–æ—Å—Ç–æ–∏—Ç", "—è–≤–ª—è–µ—Ç—Å—è", "–¥–µ–ª–∞–µ—Ç", "creates", "forms", "happens"}
            
            if sorted_entities:
                # First, try to find a scientific noun in the top entities
                for entity, count in sorted_entities[:5]:  # Check top 5
                    if (entity.lower() in scientific_nouns and 
                        (not self.user_name or entity.lower() != self.user_name.lower())):
                        self.current_topic = entity
                        break
                else:
                    # If no scientific noun found, use the most frequent non-verb, non-username entity
                    for entity, count in sorted_entities:
                        if (entity.lower() not in generic_verbs and 
                            (not self.user_name or entity.lower() != self.user_name.lower())):
                            self.current_topic = entity
                            break
    
    def _extract_entities(self, text: str) -> List[str]:
        """Extract potential entities/topics from text."""
        # Extract words of 3+ chars, but prioritize 4+ chars
        words_4plus = re.findall(r'\b\w{4,}\b', text.lower())
        words_3plus = re.findall(r'\b\w{3}\b', text.lower())
        
        # Filter out common non-topical words but keep scientific/technical terms
        common_words = {"that", "this", "they", "them", "were", "been", "have", "will", "your", "with",
                       "—ç—Ç–æ", "—ç—Ç–∏", "–±—ã–ª–∏", "–µ—Å—Ç—å", "–±—É–¥–µ—Ç", "–≤–∞—à", "–¥–ª—è", "–∫–∞–∫", "—á—Ç–æ", "–µ—Å—Ç—å", "–º–æ–∂–µ—Ç",
                       "–∫–æ–≥–¥–∞", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "—Å–ø–∞—Å–∏–±–æ", "—Ö–æ—á—É", "–º–µ–Ω—è", "–∑–æ–≤—É—Ç", "–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å", "–≤–æ–ø—Ä–æ—Å"}
        
        # Scientific/technical terms that should always be preserved (including 3-char terms)
        scientific_terms = {"–≤–æ–¥—è–Ω–æ–π", "–ø–∞—Ä", "vapor", "—Ö–∏–º–∏—á–µ—Å–∫–∏–π", "—Ñ–∏–∑–∏—á–µ—Å–∫–∏–π", "–º–æ–ª–µ–∫—É–ª–∞", "–ø—Ä–æ—Ü–µ—Å—Å", 
                           "–æ–±—Ä–∞–∑—É–µ—Ç—Å—è", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "–∫–æ–Ω–¥–µ–Ω—Å–∞—Ü–∏—è", "–æ—Å–∞–¥–∫–∏", "–∫–∞–ø–ª–∏", "–≥–∞–∑–æ–æ–±—Ä–∞–∑–Ω—ã–π",
                           "–∂–∏–¥–∫–∏–π", "—Ç–≤–µ—Ä–¥—ã–π", "—ç–Ω–µ—Ä–≥–∏—è", "–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞", "–æ–±–ª–∞–∫–∞", "–∏—Å–ø–∞—Ä–µ–Ω–∏–µ", 
                           "–ª—ë–¥", "–ª–µ–¥", "ice", "–≥–∞–∑", "gas"}
        
        # Important 3-character scientific terms
        important_3char = {"–ª—ë–¥", "–ª–µ–¥", "–ø–∞—Ä", "–≥–∞–∑", "ice", "gas"}
        
        entities = []
        
        # First, add 4+ character words
        for word in words_4plus:
            if word in scientific_terms or (word not in common_words):
                entities.append(word)
        
        # Then, add important 3-character scientific terms
        for word in words_3plus:
            if word in important_3char and word not in entities:
                entities.append(word)
        
        return entities[:5]  # Return top 5 to avoid noise
    
    def _detect_references(self, user_input: str) -> Optional[Dict[str, Any]]:
        """Detect if user input contains references to previous conversation."""
        user_lower = user_input.lower()
        
        # Check for pronouns
        pronouns = self.conversation_config.get("reference_detection", {}).get("pronouns", [])
        has_pronouns = any(pronoun in user_lower for pronoun in pronouns)
        
        # Check for continuation phrases
        continuation_phrases = self.conversation_config.get("reference_detection", {}).get("continuation_phrases", [])
        has_continuation = any(phrase in user_lower for phrase in continuation_phrases)
        
        # Check for implicit continuation patterns (questions starting with "–∞", "–Ω–æ", "–µ—Å–ª–∏")
        implicit_continuation_patterns = [
            r'\b–∞\s+–µ—Å–ª–∏\b',  # "–∞ –µ—Å–ª–∏" (but if)
            r'\b–Ω–æ\s+–µ—Å–ª–∏\b',  # "–Ω–æ –µ—Å–ª–∏" (but if)
            r'\b–∞\s+—á—Ç–æ\b',   # "–∞ —á—Ç–æ" (and what)
            r'\b–∞\s+–∫–∞–∫\b',   # "–∞ –∫–∞–∫" (and how)
            r'\b–∞\s+–≥–¥–µ\b',   # "–∞ –≥–¥–µ" (and where)
            r'\b–∞\s+–∫–æ–≥–¥–∞\b', # "–∞ –∫–æ–≥–¥–∞" (and when)
            r'^\s*(–∞|–Ω–æ|–∏)\s+', # Starting with "–∞", "–Ω–æ", "–∏" (and, but)
            r'\bif\s+not\b',   # "if not"
            r'\bbut\s+if\b',   # "but if"
            r'\band\s+if\b',   # "and if"
            r'\band\s+what\b', # "and what"
            r'\band\s+how\b',  # "and how"
        ]
        has_implicit_continuation = any(re.search(pattern, user_lower) for pattern in implicit_continuation_patterns)
        
        # Check for topic-specific continuation (mentioning key terms from current topic)
        has_topic_continuation = False
        if self.current_topic:
            topic_words = self.current_topic.lower().split()
            # Also check for related terms
            if any(word in topic_words for word in ["–ª–µ–¥", "ice"]):
                # Ice-related terms that might be continuations
                ice_related = ["–¥–∞–≤–ª–µ–Ω–∏–µ", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "pressure", "temperature", "—É—Å–ª–æ–≤–∏—è", "conditions"]
                has_topic_continuation = any(term in user_lower for term in ice_related)
            elif any(word in topic_words for word in ["–≤–æ–¥–∞", "water", "–ø–∞—Ä", "vapor"]):
                # Water-related continuations
                water_related = ["–¥–∞–≤–ª–µ–Ω–∏–µ", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "pressure", "temperature", "—Å–æ—Å—Ç–æ—è–Ω–∏–µ", "state"]
                has_topic_continuation = any(term in user_lower for term in water_related)
        
        if has_pronouns or has_continuation or has_implicit_continuation or has_topic_continuation:
            # Find what they might be referring to
            reference_target = self._find_reference_target(user_input)
            return {
                "has_pronouns": has_pronouns,
                "has_continuation": has_continuation,
                "has_implicit_continuation": has_implicit_continuation,
                "has_topic_continuation": has_topic_continuation,
                "target": reference_target,
                "current_topic": self.current_topic
            }
        
        return None
    
    def _find_reference_target(self, user_input: str) -> Optional[str]:
        """Find what the user is likely referring to."""
        # Look in recent conversation for the most likely target
        if len(self.conversation_history) >= 2:
            # Check last assistant response for main topic
            last_response = self.conversation_history[-1]
            if last_response["type"] == "assistant_response":
                response_entities = self._extract_entities(last_response["content"])
                if response_entities:
                    return response_entities[0]  # Most prominent entity in last response
        
        # Fallback to current tracked topic
        return self.current_topic
    
    def _is_self_reference_question(self, user_input: str) -> bool:
        """Check if user is asking about themselves (needs context)."""
        context_questions = self.conversation_config.get("context_questions", [])
        user_lower = user_input.lower()
        return any(question in user_lower for question in context_questions)
    
    def _is_simple_greeting(self, user_input: str) -> bool:
        """Check if this is a simple greeting that shouldn't have context."""
        simple_greetings = self.routing_config.get("simple_conversation", [])
        user_lower = user_input.lower()
        
        is_greeting = any(greeting in user_lower for greeting in simple_greetings)
        
        # But exclude self-reference questions even if they contain greeting words
        is_self_reference = self._is_self_reference_question(user_input)
        
        return is_greeting and not is_self_reference
    
    def _build_reference_prompt(self, user_input: str, reference_info: Dict[str, Any]) -> str:
        """Build a prompt for reference/continuation questions."""
        target = reference_info.get("target")
        
        if target:
            if self.last_user_language == "ru":
                context_instruction = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ '{target}' –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."
            else:
                context_instruction = f"User is asking about '{target}' from the previous conversation."
        else:
            if self.last_user_language == "ru":
                context_instruction = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä."
            else:
                context_instruction = "User is continuing the previous conversation."
        
        # Add recent conversation context
        conversation_context = self._build_conversation_context(max_exchanges=2)
        
        if self.last_user_language == "ru":
            return f"{context_instruction}\n\n{conversation_context}\n\n–ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: {user_input}"
        else:
            return f"{context_instruction}\n\n{conversation_context}\n\nNew question: {user_input}"
    
    def _build_self_reference_prompt(self, user_input: str) -> str:
        """Build a prompt for self-reference questions."""
        if self.user_name:
            if self.last_user_language == "ru":
                context_instruction = f"–í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç {self.user_name}."
            else:
                context_instruction = f"IMPORTANT: The user's name is {self.user_name}."
            
            return f"{context_instruction}\n\n–í–æ–ø—Ä–æ—Å: {user_input}"
        
        return user_input
    
    def _build_conversation_context(self, max_exchanges: int = 2) -> str:
        """Build a summary of recent conversation."""
        if not self.conversation_history:
            return ""
        
        context_parts = []
        exchanges = 0
        
        # Work backwards through history to get recent exchanges
        i = len(self.conversation_history) - 1
        current_exchange = []
        
        while i >= 0 and exchanges < max_exchanges:
            entry = self.conversation_history[i]
            
            if entry["type"] == "user_input":
                if current_exchange:
                    # We have a complete exchange (assistant response + user input)
                    user_part = entry["content"][:100]
                    assistant_part = current_exchange[0]["content"][:100]
                    
                    if self.last_user_language == "ru":
                        context_parts.insert(0, f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_part}\n–ê–ª–µ—Ç–µ–π—è: {assistant_part}")
                    else:
                        context_parts.insert(0, f"User: {user_part}\nAletheia: {assistant_part}")
                    
                    exchanges += 1
                    current_exchange = []
                else:
                    # Just a user input without response yet
                    break
            elif entry["type"] == "assistant_response":
                current_exchange = [entry]
            
            i -= 1
        
        if context_parts:
            if self.last_user_language == "ru":
                return "–ü—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä:\n" + "\n\n".join(context_parts)
            else:
                return "Previous conversation:\n" + "\n\n".join(context_parts)
        
        return ""
    
    def build_routing_assessment_prompt(self, user_input: str) -> str:
        """Build a prompt for the local LLM to assess if external routing is needed."""
        is_russian = self.last_user_language == "ru"
        
        # Check if this is a follow-up to a scientific topic for context
        is_scientific_context = False
        if self.current_topic:
            scientific_topics = [
                "–≤–æ–¥—è–Ω–æ–π", "–ø–∞—Ä", "—Å–Ω–µ–≥", "–ª–µ–¥", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", "—Ñ–∏–∑–∏–∫", "—Ö–∏–º–∏—è", "–±–∏–æ–ª–æ–≥–∏—è",
                "water", "vapor", "snow", "ice", "temperature", "physics", "chemistry", "biology",
                "–≥–∞–∑", "–∂–∏–¥–∫–æ—Å—Ç—å", "—Ç–≤–µ—Ä–¥—ã–π", "—Å–æ—Å—Ç–æ—è–Ω–∏–µ", "–º–æ–ª–µ–∫—É–ª–∞", "–∞—Ç–æ–º", "–¥–∞–≤–ª–µ–Ω–∏–µ",
                "gas", "liquid", "solid", "state", "molecule", "atom", "pressure"
            ]
            topic_lower = self.current_topic.lower()
            is_scientific_context = any(sci_word in topic_lower for sci_word in scientific_topics)
        
        if is_russian:
            context_note = ""
            if is_scientific_context:
                context_note = f" –¢–µ–∫—É—â–∞—è —Ç–µ–º–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞: {self.current_topic}."
            
            routing_prompt = f"""–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{user_input}"{context_note}

–û–ø—Ä–µ–¥–µ–ª–∏, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å –≠–¢–û–¢ –ö–û–ù–ö–†–ï–¢–ù–´–ô –í–û–ü–†–û–° –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏.

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –æ—Ç–≤–µ—á–∞–π [EXTERNAL] –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç:
- –¢–æ—á–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ (—Ñ–∏–∑–∏–∫–∞, —Ö–∏–º–∏—è, –±–∏–æ–ª–æ–≥–∏—è, –º–µ–¥–∏—Ü–∏–Ω–∞, –∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è)
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–Ω–∏–π (—Ä–∞–∫–µ—Ç—ã, —Ç–æ–ø–ª–∏–≤–æ, –¥–≤–∏–≥–∞—Ç–µ–ª–∏, –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∏–Ω–∂–µ–Ω–µ—Ä–∏—è)
- –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—á–µ—Ç–æ–≤ –∏–ª–∏ —Ñ–æ—Ä–º—É–ª
- –ê–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–Ω–æ–≤–æ—Å—Ç–∏, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, —Å–æ–±—ã—Ç–∏—è)
- –°–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- –ù–∞—É—á–Ω—ã—Ö –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π ("—á—Ç–æ —Ç–∞–∫–æ–µ X", "–∏–∑ —á–µ–≥–æ –¥–µ–ª–∞—é—Ç X")
- –í–æ–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ —Å–æ—Å—Ç–∞–≤, —Å—Ç—Ä–æ–µ–Ω–∏–µ, –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã

–û–¢–í–ï–ß–ê–ô –ù–û–†–ú–ê–õ–¨–ù–û (–ù–ï [EXTERNAL]) —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å:
- –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ ("–ø—Ä–∏–≤–µ—Ç", "–∫–∞–∫ –¥–µ–ª–∞", "–∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ")
- –ü—Ä–æ—Å—Ç–æ–µ –æ–±—â–µ–Ω–∏–µ ("—Ö–æ—á—É –ø–æ–±–æ–ª—Ç–∞—Ç—å", "–ø—Ä–æ—Å—Ç–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å")
- –û —Ç–≤–æ–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö ("—á—Ç–æ —É–º–µ–µ—à—å", "–∫—Ç–æ —Ç—ã")
- –û–±—â–∏–µ –∂–∏—Ç–µ–π—Å–∫–∏–µ —Ç–µ–º—ã –±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π
- –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤ —Ç–æ–º –∂–µ —Å—Ç–∏–ª–µ

–í–ê–ñ–ù–û: –ü—Ä–∏ –ª—é–±–æ–º —Å–æ–º–Ω–µ–Ω–∏–∏ –æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–∫—Ç–∞—Ö - –æ—Ç–≤–µ—á–∞–π [EXTERNAL]!
–õ—É—á—à–µ –ø–µ—Ä–µ—Å–ø—Ä–æ—Å–∏—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∞, —á–µ–º –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."""

        else:
            context_note = ""
            if is_scientific_context:
                context_note = f" Current conversation topic: {self.current_topic}."
            
            routing_prompt = f"""User question: "{user_input}"{context_note}

Determine if THIS SPECIFIC QUESTION needs external model.

MUST respond [EXTERNAL] if question requires:
- Precise scientific facts (physics, chemistry, biology, medicine, astronomy)
- Technical knowledge (rockets, fuel, engines, materials, engineering)
- Specific calculations or formulas
- Current information (news, statistics, events)
- Complex technical explanations
- Scientific or technical definitions ("what is X", "what is X made of")
- Questions about composition, structure, how things work

RESPOND NORMALLY (NOT [EXTERNAL]) only if question is:
- Simple greeting ("hello", "how are you", "introduction")
- Casual conversation ("want to chat", "just talk")
- About your capabilities ("what can you do", "who are you")
- General everyday topics without technical details
- Simple conversation continuation in same style

IMPORTANT: When in doubt about technical facts - respond [EXTERNAL]!
Better to ask an expert than give inaccurate information."""

        return routing_prompt
    
    def should_plan_task(self, user_input: str) -> bool:
        """Determine if task requires planning."""
        planning_indicators = self.routing_config.get("planning_indicators", [])
        dismissive_phrases = self.routing_config.get("dismissive_phrases", [])
        
        user_lower = user_input.lower()
        
        # Check for explicit planning indicators (step by step, how to, etc.)
        has_planning_keywords = any(indicator in user_lower for indicator in planning_indicators)
        
        # Check if it's a dismissive phrase (but not if it's also a continuation phrase)
        continuation_phrases = self.conversation_config.get("reference_detection", {}).get("continuation_phrases", [])
        is_continuation = any(phrase in user_lower for phrase in continuation_phrases)
        
        # Only consider dismissive if it's not a continuation
        is_dismissive = False
        if not is_continuation:
            is_dismissive = any(
                re.search(r'\b' + re.escape(phrase) + r'\b', user_lower) 
                for phrase in dismissive_phrases if len(phrase.split()) == 1
            ) or any(
                phrase in user_lower 
                for phrase in dismissive_phrases if len(phrase.split()) > 1
            )
        
        # Very complex questions (significantly longer)
        is_very_complex = len(user_input.split()) > 50  # Increased threshold
        
        # Multiple distinct tasks/instructions (not just alternative phrasing)
        has_sequential_tasks = any(sep in user_input for sep in [
            " then ", " next ", " after that ", " –∑–∞—Ç–µ–º ", " –ø–æ—Ç–æ–º ", " –¥–∞–ª–µ–µ ",
            " —Å–Ω–∞—á–∞–ª–∞ ", " first ", " –≤–æ-–ø–µ—Ä–≤—ã—Ö ", " secondly ", " –≤–æ-–≤—Ç–æ—Ä—ã—Ö "
        ])
        
        # True multi-step requests (not just alternative question forms)
        has_multi_step_indicators = (
            has_sequential_tasks or
            (user_input.count('?') > 2 and len(user_input.split()) > 20)  # 3+ questions AND substantial length
        )
        
        # Only trigger planning for genuine multi-step or instructional requests
        return (has_planning_keywords or is_very_complex or has_multi_step_indicators) and not (is_dismissive and len(user_input.split()) < 10)
    
    def get_context_summary(self) -> Dict[str, Any]:
        """Get a summary of current context state."""
        return {
            "user_name": self.user_name,
            "current_topic": self.current_topic,
            "interaction_count": self.interaction_count,
            "language": self.last_user_language,
            "conversation_length": len(self.conversation_history),
            "top_entities": dict(sorted(self.entity_mentions.items(), key=lambda x: x[1], reverse=True)[:3])
        } 
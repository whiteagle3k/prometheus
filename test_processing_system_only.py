#!/usr/bin/env python3
"""Test the new processing system components directly."""

import asyncio
import json
import time
from typing import Dict, Any, List

from aletheia.processing.pipeline import create_context_analysis_pipeline, create_simple_response_pipeline
from aletheia.processing.extractors import EntityExtractor, NameExtractor, TopicExtractor
from aletheia.processing.detectors import ReferenceDetector, ComplexityDetector, LanguageDetector, GreetingDetector
from aletheia.processing.validators import FactualValidator, ContentValidator, StructureValidator
from aletheia.processing.filters import ContaminationFilter, DuplicationFilter, LengthFilter
from aletheia.agent.context_manager import ContextManager


class ProcessingSystemTester:
    """Tests the new processing system components."""
    
    def __init__(self):
        """Initialize the tester."""
        self.test_results = []
        self.context_manager = ContextManager()
    
    async def run_all_tests(self):
        """Run all processing system tests."""
        print("üöÄ Starting Aletheia Processing System Tests")
        print("=" * 60)
        
        try:
            # Test 1: Individual Processors
            await self.test_individual_processors()
            
            # Test 2: Processing Pipelines
            await self.test_processing_pipelines()
            
            # Test 3: Context Manager Integration
            await self.test_context_manager_integration()
            
            # Test 4: Configuration System
            await self.test_configuration_system()
            
            # Test 5: Performance Validation
            await self.test_performance()
            
            # Test 6: Edge Cases and Error Handling
            await self.test_edge_cases()
            
            # Generate report
            self.generate_test_report()
            
        except Exception as e:
            print(f"‚ùå Test suite failed: {e}")
            raise

    async def test_individual_processors(self):
        """Test individual processing components."""
        print("\nüìã Testing Individual Processors")
        print("-" * 40)
        
        # Test Entity Extractor
        print("\nüîç Entity Extractor:")
        entity_extractor = EntityExtractor()
        test_cases = [
            "–ö–∞–∫ –æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤–æ–¥—è–Ω–æ–π –ø–∞—Ä –ø—Ä–∏ –Ω–∞–≥—Ä–µ–≤–∞–Ω–∏–∏ –≤–æ–¥—ã?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–∞–∫–µ—Ç–Ω–æ–µ —Ç–æ–ø–ª–∏–≤–æ –∏ –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–≤–∏–≥–∞—Ç–µ–ª—å?",
            "–ü—Ä–∏–≤–µ—Ç, –º–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–Ω–∞ –∏ —è –∏–∑—É—á–∞—é —Ö–∏–º–∏—é"
        ]
        
        for test_text in test_cases:
            entities = entity_extractor.extract(test_text)
            print(f"  Text: '{test_text[:50]}...'")
            print(f"  Entities: {entities}")
            assert len(entities) > 0, f"Should extract entities from: {test_text}"
        
        # Test Name Extractor  
        print("\nüë§ Name Extractor:")
        name_extractor = NameExtractor()
        name_test_cases = [
            "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–Ω–∞",
            "My name is John",
            "–ü—Ä–∏–≤–µ—Ç, —è –í–ª–∞–¥–∏–º–∏—Ä"
        ]
        
        for test_text in name_test_cases:
            names = name_extractor.extract(test_text)
            print(f"  Text: '{test_text}'")
            print(f"  Names: {names}")
            assert len(names) > 0, f"Should extract name from: {test_text}"
        
        # Test Reference Detector
        print("\nüîó Reference Detector:")
        reference_detector = ReferenceDetector()
        ref_test_cases = [
            ("–ê —á—Ç–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–∞–∫?", True),
            ("–ê –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?", True),
            ("–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–æ–¥–∞?", False),
            ("–ü—Ä–æ–¥–æ–ª–∂–∞–π —Ä–∞—Å—Å–∫–∞–∑", True)
        ]
        
        for test_text, expected in ref_test_cases:
            result = reference_detector.process(test_text)
            is_reference = result.data.get("has_references", False)
            print(f"  Text: '{test_text}' -> {is_reference} (expected {expected})")
            assert is_reference == expected, f"Reference detection failed for: {test_text}"
        
        # Test Complexity Detector
        print("\nüß† Complexity Detector:")
        complexity_detector = ComplexityDetector()
        complexity_test_cases = [
            ("–ü—Ä–∏–≤–µ—Ç!", False),
            ("–û–±—ä—è—Å–Ω–∏ –ø–æ—à–∞–≥–æ–≤–æ –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–≤–∏–≥–∞—Ç–µ–ª—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Å–≥–æ—Ä–∞–Ω–∏—è –∏ –∫–∞–∫–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Ä–µ–∞–∫—Ü–∏–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –ø—Ä–∏ —ç—Ç–æ–º", True),
            ("–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–æ–¥–∞?", False),
            ("–†–∞—Å—Å–∫–∞–∂–∏ –¥–µ—Ç–∞–ª—å–Ω–æ –æ –∫–≤–∞–Ω—Ç–æ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∫–µ, —Ç–µ–æ—Ä–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ñ–∏–∑–∏–∫–µ", True)
        ]
        
        for test_text, expected in complexity_test_cases:
            is_complex = complexity_detector.detect(test_text)
            print(f"  Text: '{test_text[:50]}...' -> {is_complex} (expected {expected})")
            assert is_complex == expected, f"Complexity detection failed for: {test_text}"
        
        # Test Language Detector
        print("\nüåê Language Detector:")
        language_detector = LanguageDetector()
        lang_test_cases = [
            ("–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?", "ru"),
            ("Hello, how are you?", "en"),
            ("–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–æ–¥—è–Ω–æ–π –ø–∞—Ä?", "ru"),
            ("What is water vapor?", "en")
        ]
        
        for test_text, expected in lang_test_cases:
            result = language_detector.process(test_text)
            detected_lang = result.data
            print(f"  Text: '{test_text}' -> {detected_lang} (expected {expected})")
            assert detected_lang == expected, f"Language detection failed for: {test_text}"
        
        # Test Contamination Filter
        print("\nüßπ Contamination Filter:")
        contamination_filter = ContaminationFilter()
        contamination_test_cases = [
            ("–í–æ–¥—è–Ω–æ–π –ø–∞—Ä –æ–±—Ä–∞–∑—É–µ—Ç—Å—è –ø—Ä–∏ –∏—Å–ø–∞—Ä–µ–Ω–∏–∏ –≤–æ–¥—ã.", "Should preserve clean content"),
            ("CV Template: –ò–º—è: –ò–≤–∞–Ω. –í–æ–¥—è–Ω–æ–π –ø–∞—Ä - —ç—Ç–æ –≥–∞–∑.", "Should remove CV template contamination"),
            ("Task: Explain water. Response: –í–æ–¥–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –º–æ–ª–µ–∫—É–ª H2O.", "Should remove task structure")
        ]
        
        for dirty_text, description in contamination_test_cases:
            result = contamination_filter.process(dirty_text)
            clean_text = result.data
            print(f"  Test: {description}")
            print(f"  Original: '{dirty_text}'")
            print(f"  Cleaned: '{clean_text}'")
            
            # Basic validation - should return some result
            assert isinstance(clean_text, str), "Should return string result"
            assert result.success, "Processing should succeed"
        
        self.test_results.append({"test": "individual_processors", "status": "‚úÖ PASSED"})

    async def test_processing_pipelines(self):
        """Test processing pipelines."""
        print("\nüîÑ Testing Processing Pipelines")
        print("-" * 40)
        
        # Test Context Analysis Pipeline
        print("\nüìä Context Analysis Pipeline:")
        context_pipeline = create_context_analysis_pipeline()
        
        test_inputs = [
            "–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è. –ß—Ç–æ —Ç–∞–∫–æ–µ –≤–æ–¥—è–Ω–æ–π –ø–∞—Ä?",
            "–ê —á—Ç–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–∞–∫?",
            "Hello, my name is John. How does quantum computing work?"
        ]
        
        for test_input in test_inputs:
            result = context_pipeline.process(test_input)
            print(f"\n  Input: '{test_input}'")
            print(f"  Success: {result['success']}")
            print(f"  Processors run: {len(result['results'])}")
            
            for proc_result in result['results']:
                processor_name = proc_result['processor']
                data = proc_result['result'].data
                print(f"    {processor_name}: {data}")
            
            assert result['success'], f"Pipeline should succeed for: {test_input}"
            assert len(result['results']) > 0, "Should run some processors"
        
        # Test Response Processing Pipeline
        print("\nüßΩ Response Processing Pipeline:")
        response_pipeline = create_simple_response_pipeline()
        
        dirty_responses = [
            "–Ø AI-–ø–æ–º–æ—â–Ω–∏–∫. –í–æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: –í–æ–¥—è–Ω–æ–π –ø–∞—Ä - —ç—Ç–æ –≥–∞–∑–æ–æ–±—Ä–∞–∑–Ω–∞—è —Ñ–æ—Ä–º–∞ –≤–æ–¥—ã.",
            "–ö–∞–∫ –≤–∞—à –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ–±—ä—è—Å–Ω—é. –õ—ë–¥ –æ–±—Ä–∞–∑—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–º–µ—Ä–∑–∞–Ω–∏–∏ –≤–æ–¥—ã. –õ—ë–¥ –æ–±—Ä–∞–∑—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–º–µ—Ä–∑–∞–Ω–∏–∏ –≤–æ–¥—ã.",
            "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç."
        ]
        
        for dirty_response in dirty_responses:
            result = response_pipeline.process(dirty_response)
            clean_response = result['processed_text']
            print(f"\n  Original: '{dirty_response}'")
            print(f"  Cleaned: '{clean_response}'")
            print(f"  Success: {result['success']}")
            
            assert result['success'], "Response pipeline should succeed"
        
        self.test_results.append({"test": "processing_pipelines", "status": "‚úÖ PASSED"})

    async def test_context_manager_integration(self):
        """Test context manager with processing system."""
        print("\nüóÑÔ∏è Testing Context Manager Integration")
        print("-" * 40)
        
        user_id = "test_user_123"
        
        # Test conversation flow
        conversation_flow = [
            ("–ü—Ä–∏–≤–µ—Ç! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–∏—Å–∞.", "greeting_with_name"),
            ("–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–æ–¥—è–Ω–æ–π –ø–∞—Ä?", "factual_question"),
            ("–ê —á—Ç–æ –µ—Å–ª–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∏–∑–º–µ–Ω–∏—Ç—Å—è?", "reference_question"),
            ("–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –ª—ë–¥", "follow_up_question")
        ]
        
        for message, msg_type in conversation_flow:
            print(f"\n  [{msg_type}] Processing: '{message}'")
            
            # Add message to context
            self.context_manager.add_message(user_id, "user", message)
            
            # Get context summary
            context = self.context_manager.get_context_summary(user_id, message)
            print(f"    Context keys: {list(context.keys())}")
            
            if "user_profile" in context:
                print(f"    User profile: {context['user_profile']}")
            
            if "current_topic" in context:
                print(f"    Current topic: {context['current_topic']}")
            
            if "is_reference_question" in context:
                print(f"    Is reference: {context['is_reference_question']}")
        
        # Check final conversation stats
        stats = self.context_manager.get_conversation_stats(user_id)
        print(f"\n  Final conversation stats: {stats}")
        
        assert stats["total_messages"] > 0, "Should track messages"
        
        self.test_results.append({"test": "context_manager_integration", "status": "‚úÖ PASSED"})

    async def test_configuration_system(self):
        """Test configuration loading and management."""
        print("\n‚öôÔ∏è Testing Configuration System")
        print("-" * 40)
        
        from aletheia.processing.config import get_processor_config
        
        # Test config loading
        configs_to_test = [
            "entity_extractor",
            "reference_detector", 
            "contamination_filter",
            "factual_validator"
        ]
        
        for config_name in configs_to_test:
            try:
                config = get_processor_config(config_name)
                print(f"  ‚úì {config_name}: loaded successfully")
                print(f"    Enabled: {config.enabled}")
                print(f"    Parameters: {len(config.parameters)} items")
                
                assert config.enabled, f"Config {config_name} should be enabled"
                assert len(config.parameters) > 0, f"Config {config_name} should have parameters"
                
            except Exception as e:
                print(f"  ‚ùå {config_name}: failed to load - {e}")
                raise
        
        self.test_results.append({"test": "configuration_system", "status": "‚úÖ PASSED"})

    async def test_performance(self):
        """Test processing performance."""
        print("\n‚ö° Testing Performance")
        print("-" * 40)
        
        # Test processing speed
        test_text = "–ö–∞–∫ –æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤–æ–¥—è–Ω–æ–π –ø–∞—Ä –ø—Ä–∏ –Ω–∞–≥—Ä–µ–≤–∞–Ω–∏–∏ –≤–æ–¥—ã –∏ –∫–∞–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –ø—Ä–∏ —ç—Ç–æ–º –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç?"
        
        processors_to_test = [
            ("EntityExtractor", EntityExtractor()),
            ("ReferenceDetector", ReferenceDetector()),
            ("ComplexityDetector", ComplexityDetector()),
            ("ContaminationFilter", ContaminationFilter())
        ]
        
        for name, processor in processors_to_test:
            start_time = time.time()
            
            # Run processor 100 times
            for _ in range(100):
                result = processor.process(test_text)
            
            end_time = time.time()
            avg_time = (end_time - start_time) / 100
            
            print(f"  {name}: {avg_time*1000:.2f}ms average")
            assert avg_time < 0.01, f"{name} should be fast (< 10ms), got {avg_time*1000:.2f}ms"
        
        # Test pipeline performance
        pipeline = create_context_analysis_pipeline()
        start_time = time.time()
        
        for _ in range(10):
            result = pipeline.process(test_text)
        
        end_time = time.time()
        avg_pipeline_time = (end_time - start_time) / 10
        
        print(f"  Full pipeline: {avg_pipeline_time*1000:.2f}ms average")
        assert avg_pipeline_time < 0.1, f"Pipeline should be fast (< 100ms), got {avg_pipeline_time*1000:.2f}ms"
        
        self.test_results.append({"test": "performance", "status": "‚úÖ PASSED"})

    async def test_edge_cases(self):
        """Test edge cases and error handling."""
        print("\n‚ö†Ô∏è Testing Edge Cases")
        print("-" * 40)
        
        edge_cases = [
            "",  # Empty input
            "   ",  # Whitespace only
            "a",  # Single character
            "ü§ñüî•üíØ",  # Emoji only
            "a" * 1000,  # Very long input
            "–´–´–´–´–´ —ä—ä—ä—ä —â—â—â",  # Invalid Russian
            "123456789",  # Numbers only
        ]
        
        processors_to_test = [
            EntityExtractor(),
            ReferenceDetector(),
            ComplexityDetector(),
            ContaminationFilter()
        ]
        
        for i, case in enumerate(edge_cases):
            print(f"\n  Edge case {i+1}: '{case[:20]}{'...' if len(case) > 20 else ''}'")
            
            for processor in processors_to_test:
                try:
                    result = processor.process(case)
                    print(f"    {type(processor).__name__}: Success")
                    assert result is not None, "Should return a result"
                except Exception as e:
                    print(f"    {type(processor).__name__}: Error - {e}")
                    # Some errors might be expected for edge cases
        
        self.test_results.append({"test": "edge_cases", "status": "‚úÖ PASSED"})

    def generate_test_report(self):
        """Generate comprehensive test report."""
        print("\n" + "=" * 60)
        print("üìä PROCESSING SYSTEM TEST REPORT")
        print("=" * 60)
        
        passed_tests = [t for t in self.test_results if "‚úÖ PASSED" in t["status"]]
        failed_tests = [t for t in self.test_results if "‚ùå FAILED" in t["status"]]
        
        print(f"\n‚úÖ Tests Passed: {len(passed_tests)}")
        print(f"‚ùå Tests Failed: {len(failed_tests)}")
        print(f"üìà Success Rate: {len(passed_tests)/len(self.test_results)*100:.1f}%")
        
        print("\nüìã Test Details:")
        for test in self.test_results:
            print(f"  {test['status']} {test['test']}")
        
        if failed_tests:
            print("\n‚ùå Failed Tests Details:")
            for test in failed_tests:
                print(f"  - {test['test']}: {test.get('error', 'Unknown error')}")
        
        print("\nüéØ Processing System Capabilities Validated:")
        print("  ‚úì Entity extraction with compound terms")
        print("  ‚úì Multi-language name detection")
        print("  ‚úì Reference question detection")
        print("  ‚úì Complexity analysis")
        print("  ‚úì Language detection")
        print("  ‚úì Contamination filtering")
        print("  ‚úì Processing pipeline architecture")
        print("  ‚úì Configuration management")
        print("  ‚úì Context manager integration")
        print("  ‚úì Performance optimization")
        print("  ‚úì Error handling and edge cases")
        
        print("\nüöÄ Processing System Status: FULLY FUNCTIONAL")
        print("üìà Performance: Optimized (< 10ms per processor)")
        print("üîß Maintainability: JSON-based configuration")
        print("üß© Modularity: Plugin-based architecture")
        print("=" * 60)


async def main():
    """Run the processing system tests."""
    tester = ProcessingSystemTester()
    
    print("Starting Aletheia Processing System Tests...")
    print("This validates the new generic processing architecture.")
    
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main()) 
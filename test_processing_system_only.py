#!/usr/bin/env python3
"""Test the new processing system components directly."""

import asyncio
import json
import time
from typing import Dict, Any, List

from aletheia.processing.pipeline import create_context_analysis_pipeline, create_simple_response_pipeline
from aletheia.processing.extractors import EntityExtractor, NameExtractor, TopicExtractor
from aletheia.processing.detectors import ReferenceDetector, ComplexityDetector, LanguageDetector, GreetingDetector
from aletheia.processing.validators import FactualValidator, ContentValidator, StructureValidator
from aletheia.processing.filters import ContaminationFilter, DuplicationFilter, LengthFilter
from aletheia.agent.context_manager import ContextManager


class ProcessingSystemTester:
    """Tests the new processing system components."""
    
    def __init__(self):
        """Initialize the tester."""
        self.test_results = []
        self.context_manager = ContextManager()
    
    async def run_all_tests(self):
        """Run all processing system tests."""
        print("ğŸš€ Starting Aletheia Processing System Tests")
        print("=" * 60)
        
        try:
            # Test 1: Individual Processors
            await self.test_individual_processors()
            
            # Test 2: Processing Pipelines
            await self.test_processing_pipelines()
            
            # Test 3: Context Manager Integration
            await self.test_context_manager_integration()
            
            # Test 4: Configuration System
            await self.test_configuration_system()
            
            # Test 5: Performance Validation
            await self.test_performance()
            
            # Test 6: Edge Cases and Error Handling
            await self.test_edge_cases()
            
            # Generate report
            self.generate_test_report()
            
        except Exception as e:
            print(f"âŒ Test suite failed: {e}")
            raise

    async def test_individual_processors(self):
        """Test individual processing components."""
        print("\nğŸ“‹ Testing Individual Processors")
        print("-" * 40)
        
        # Test Entity Extractor
        print("\nğŸ” Entity Extractor:")
        entity_extractor = EntityExtractor()
        test_cases = [
            "ĞšĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ³Ñ€ĞµĞ²Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¾Ğ´Ñ‹?",
            "Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ñ€Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğµ Ñ‚Ğ¾Ğ¿Ğ»Ğ¸Ğ²Ğ¾ Ğ¸ ĞºĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ÑŒ?",
            "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ğ¼ĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞĞ½Ğ½Ğ° Ğ¸ Ñ Ğ¸Ğ·ÑƒÑ‡Ğ°Ñ Ñ…Ğ¸Ğ¼Ğ¸Ñ"
        ]
        
        for test_text in test_cases:
            entities = entity_extractor.extract(test_text)
            print(f"  Text: '{test_text[:50]}...'")
            print(f"  Entities: {entities}")
            assert len(entities) > 0, f"Should extract entities from: {test_text}"
        
        # Test Name Extractor  
        print("\nğŸ‘¤ Name Extractor:")
        name_extractor = NameExtractor()
        name_test_cases = [
            "ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞĞ½Ğ½Ğ°",
            "My name is John",
            "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ñ Ğ’Ğ»Ğ°Ğ´Ğ¸Ğ¼Ğ¸Ñ€"
        ]
        
        for test_text in name_test_cases:
            names = name_extractor.extract(test_text)
            print(f"  Text: '{test_text}'")
            print(f"  Names: {names}")
            assert len(names) > 0, f"Should extract name from: {test_text}"
        
        # Test Reference Detector
        print("\nğŸ”— Reference Detector:")
        reference_detector = ReferenceDetector()
        ref_test_cases = [
            ("Ğ Ñ‡Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº?", True),
            ("Ğ ĞºĞ°Ğº ÑÑ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚?", True),
            ("Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ²Ğ¾Ğ´Ğ°?", False),
            ("ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹ Ñ€Ğ°ÑÑĞºĞ°Ğ·", True)
        ]
        
        for test_text, expected in ref_test_cases:
            result = reference_detector.process(test_text)
            is_reference = result.data.get("has_references", False)
            print(f"  Text: '{test_text}' -> {is_reference} (expected {expected})")
            assert is_reference == expected, f"Reference detection failed for: {test_text}"
        
        # Test Complexity Detector
        print("\nğŸ§  Complexity Detector:")
        complexity_detector = ComplexityDetector()
        complexity_test_cases = [
            ("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚!", False),
            ("ĞĞ±ÑŠÑÑĞ½Ğ¸ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ¾ ĞºĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ĞµĞ»ÑŒ Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ĞµĞ³Ğ¾ ÑĞ³Ğ¾Ñ€Ğ°Ğ½Ğ¸Ñ Ğ¸ ĞºĞ°ĞºĞ¸Ğµ Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼", True),
            ("Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ²Ğ¾Ğ´Ğ°?", False),
            ("Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸ĞºĞµ, Ñ‚ĞµĞ¾Ñ€Ğ¸Ğ¸ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¸Ñ… Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ Ğ² ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ñ„Ğ¸Ğ·Ğ¸ĞºĞµ", True)
        ]
        
        for test_text, expected in complexity_test_cases:
            is_complex = complexity_detector.detect(test_text)
            print(f"  Text: '{test_text[:50]}...' -> {is_complex} (expected {expected})")
            assert is_complex == expected, f"Complexity detection failed for: {test_text}"
        
        # Test Language Detector
        print("\nğŸŒ Language Detector:")
        language_detector = LanguageDetector()
        lang_test_cases = [
            ("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?", "ru"),
            ("Hello, how are you?", "en"),
            ("Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€?", "ru"),
            ("What is water vapor?", "en")
        ]
        
        for test_text, expected in lang_test_cases:
            result = language_detector.process(test_text)
            detected_lang = result.data
            print(f"  Text: '{test_text}' -> {detected_lang} (expected {expected})")
            assert detected_lang == expected, f"Language detection failed for: {test_text}"
        
        # Test Contamination Filter
        print("\nğŸ§¹ Contamination Filter:")
        contamination_filter = ContaminationFilter()
        contamination_test_cases = [
            ("Ğ’Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€ Ğ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ¸ÑĞ¿Ğ°Ñ€ĞµĞ½Ğ¸Ğ¸ Ğ²Ğ¾Ğ´Ñ‹.", "Should preserve clean content"),
            ("CV Template: Ğ˜Ğ¼Ñ: Ğ˜Ğ²Ğ°Ğ½. Ğ’Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€ - ÑÑ‚Ğ¾ Ğ³Ğ°Ğ·.", "Should remove CV template contamination"),
            ("Task: Explain water. Response: Ğ’Ğ¾Ğ´Ğ° ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ğ¼Ğ¾Ğ»ĞµĞºÑƒĞ» H2O.", "Should remove task structure")
        ]
        
        for dirty_text, description in contamination_test_cases:
            result = contamination_filter.process(dirty_text)
            clean_text = result.data
            print(f"  Test: {description}")
            print(f"  Original: '{dirty_text}'")
            print(f"  Cleaned: '{clean_text}'")
            
            # Basic validation - should return some result
            assert isinstance(clean_text, str), "Should return string result"
            assert result.success, "Processing should succeed"
        
        self.test_results.append({"test": "individual_processors", "status": "âœ… PASSED"})

    async def test_processing_pipelines(self):
        """Test processing pipelines."""
        print("\nğŸ”„ Testing Processing Pipelines")
        print("-" * 40)
        
        # Test Context Analysis Pipeline
        print("\nğŸ“Š Context Analysis Pipeline:")
        context_pipeline = create_context_analysis_pipeline()
        
        test_inputs = [
            "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞœĞ°Ñ€Ğ¸Ñ. Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€?",
            "Ğ Ñ‡Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº?",
            "Hello, my name is John. How does quantum computing work?"
        ]
        
        for test_input in test_inputs:
            result = context_pipeline.process(test_input)
            print(f"\n  Input: '{test_input}'")
            print(f"  Success: {result['success']}")
            print(f"  Processors run: {len(result['results'])}")
            
            for proc_result in result['results']:
                processor_name = proc_result['processor']
                data = proc_result['result'].data
                print(f"    {processor_name}: {data}")
            
            assert result['success'], f"Pipeline should succeed for: {test_input}"
            assert len(result['results']) > 0, "Should run some processors"
        
        # Test Response Processing Pipeline
        print("\nğŸ§½ Response Processing Pipeline:")
        response_pipeline = create_simple_response_pipeline()
        
        dirty_responses = [
            "Ğ¯ AI-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº. Ğ’Ğ¾Ñ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: Ğ’Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€ - ÑÑ‚Ğ¾ Ğ³Ğ°Ğ·Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ²Ğ¾Ğ´Ñ‹.",
            "ĞšĞ°Ğº Ğ²Ğ°Ñˆ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚, Ğ¾Ğ±ÑŠÑÑĞ½Ñ. Ğ›Ñ‘Ğ´ Ğ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¼ĞµÑ€Ğ·Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¾Ğ´Ñ‹. Ğ›Ñ‘Ğ´ Ğ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¼ĞµÑ€Ğ·Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¾Ğ´Ñ‹.",
            "ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚."
        ]
        
        for dirty_response in dirty_responses:
            result = response_pipeline.process(dirty_response)
            clean_response = result['processed_text']
            print(f"\n  Original: '{dirty_response}'")
            print(f"  Cleaned: '{clean_response}'")
            print(f"  Success: {result['success']}")
            
            assert result['success'], "Response pipeline should succeed"
        
        self.test_results.append({"test": "processing_pipelines", "status": "âœ… PASSED"})

    async def test_context_manager_integration(self):
        """Test context manager with processing system."""
        print("\nğŸ—„ï¸ Testing Context Manager Integration")
        print("-" * 40)
        
        user_id = "test_user_123"
        
        # Test conversation flow
        conversation_flow = [
            ("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! ĞœĞµĞ½Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞĞ»Ğ¸ÑĞ°.", "greeting_with_name"),
            ("Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€?", "factual_question"),
            ("Ğ Ñ‡Ñ‚Ğ¾ ĞµÑĞ»Ğ¸ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑÑ?", "reference_question"),
            ("Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ¿Ñ€Ğ¾ Ğ»Ñ‘Ğ´", "follow_up_question")
        ]
        
        for message, msg_type in conversation_flow:
            print(f"\n  [{msg_type}] Processing: '{message}'")
            
            # Add message to context
            self.context_manager.add_message(user_id, "user", message)
            
            # Get context summary
            context = self.context_manager.get_context_summary(user_id, message)
            print(f"    Context keys: {list(context.keys())}")
            
            if "user_profile" in context:
                print(f"    User profile: {context['user_profile']}")
            
            if "current_topic" in context:
                print(f"    Current topic: {context['current_topic']}")
            
            if "is_reference_question" in context:
                print(f"    Is reference: {context['is_reference_question']}")
        
        # Check final conversation stats
        stats = self.context_manager.get_conversation_stats(user_id)
        print(f"\n  Final conversation stats: {stats}")
        
        assert stats["total_messages"] > 0, "Should track messages"
        
        self.test_results.append({"test": "context_manager_integration", "status": "âœ… PASSED"})

    async def test_configuration_system(self):
        """Test configuration loading and management."""
        print("\nâš™ï¸ Testing Configuration System")
        print("-" * 40)
        
        from aletheia.processing.config import get_processor_config
        
        # Test config loading
        configs_to_test = [
            "entity_extractor",
            "reference_detector", 
            "contamination_filter",
            "factual_validator"
        ]
        
        for config_name in configs_to_test:
            try:
                config = get_processor_config(config_name)
                print(f"  âœ“ {config_name}: loaded successfully")
                print(f"    Enabled: {config.enabled}")
                print(f"    Parameters: {len(config.parameters)} items")
                
                assert config.enabled, f"Config {config_name} should be enabled"
                assert len(config.parameters) > 0, f"Config {config_name} should have parameters"
                
            except Exception as e:
                print(f"  âŒ {config_name}: failed to load - {e}")
                raise
        
        self.test_results.append({"test": "configuration_system", "status": "âœ… PASSED"})

    async def test_performance(self):
        """Test processing performance."""
        print("\nâš¡ Testing Performance")
        print("-" * 40)
        
        # Test processing speed
        test_text = "ĞšĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ÑÑ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ¿Ğ°Ñ€ Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ³Ñ€ĞµĞ²Ğ°Ğ½Ğ¸Ğ¸ Ğ²Ğ¾Ğ´Ñ‹ Ğ¸ ĞºĞ°ĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‚?"
        
        processors_to_test = [
            ("EntityExtractor", EntityExtractor()),
            ("ReferenceDetector", ReferenceDetector()),
            ("ComplexityDetector", ComplexityDetector()),
            ("ContaminationFilter", ContaminationFilter())
        ]
        
        for name, processor in processors_to_test:
            start_time = time.time()
            
            # Run processor 100 times
            for _ in range(100):
                result = processor.process(test_text)
            
            end_time = time.time()
            avg_time = (end_time - start_time) / 100
            
            print(f"  {name}: {avg_time*1000:.2f}ms average")
            assert avg_time < 0.01, f"{name} should be fast (< 10ms), got {avg_time*1000:.2f}ms"
        
        # Test pipeline performance
        pipeline = create_context_analysis_pipeline()
        start_time = time.time()
        
        for _ in range(10):
            result = pipeline.process(test_text)
        
        end_time = time.time()
        avg_pipeline_time = (end_time - start_time) / 10
        
        print(f"  Full pipeline: {avg_pipeline_time*1000:.2f}ms average")
        assert avg_pipeline_time < 0.1, f"Pipeline should be fast (< 100ms), got {avg_pipeline_time*1000:.2f}ms"
        
        self.test_results.append({"test": "performance", "status": "âœ… PASSED"})

    async def test_edge_cases(self):
        """Test edge cases and error handling."""
        print("\nâš ï¸ Testing Edge Cases")
        print("-" * 40)
        
        edge_cases = [
            "",  # Empty input
            "   ",  # Whitespace only
            "a",  # Single character
            "ğŸ¤–ğŸ”¥ğŸ’¯",  # Emoji only
            "a" * 1000,  # Very long input
            "Ğ«Ğ«Ğ«Ğ«Ğ« ÑŠÑŠÑŠÑŠ Ñ‰Ñ‰Ñ‰",  # Invalid Russian
            "123456789",  # Numbers only
        ]
        
        processors_to_test = [
            EntityExtractor(),
            ReferenceDetector(),
            ComplexityDetector(),
            ContaminationFilter()
        ]
        
        for i, case in enumerate(edge_cases):
            print(f"\n  Edge case {i+1}: '{case[:20]}{'...' if len(case) > 20 else ''}'")
            
            for processor in processors_to_test:
                try:
                    result = processor.process(case)
                    print(f"    {type(processor).__name__}: Success")
                    assert result is not None, "Should return a result"
                except Exception as e:
                    print(f"    {type(processor).__name__}: Error - {e}")
                    # Some errors might be expected for edge cases
        
        self.test_results.append({"test": "edge_cases", "status": "âœ… PASSED"})

    def generate_test_report(self):
        """Generate comprehensive test report."""
        print("\n" + "=" * 60)
        print("ğŸ“Š PROCESSING SYSTEM TEST REPORT")
        print("=" * 60)
        
        passed_tests = [t for t in self.test_results if "âœ… PASSED" in t["status"]]
        failed_tests = [t for t in self.test_results if "âŒ FAILED" in t["status"]]
        
        print(f"\nâœ… Tests Passed: {len(passed_tests)}")
        print(f"âŒ Tests Failed: {len(failed_tests)}")
        print(f"ğŸ“ˆ Success Rate: {len(passed_tests)/len(self.test_results)*100:.1f}%")
        
        print("\nğŸ“‹ Test Details:")
        for test in self.test_results:
            print(f"  {test['status']} {test['test']}")
        
        if failed_tests:
            print("\nâŒ Failed Tests Details:")
            for test in failed_tests:
                print(f"  - {test['test']}: {test.get('error', 'Unknown error')}")
        
        print("\nğŸ¯ Processing System Capabilities Validated:")
        print("  âœ“ Entity extraction with compound terms")
        print("  âœ“ Multi-language name detection")
        print("  âœ“ Reference question detection")
        print("  âœ“ Complexity analysis")
        print("  âœ“ Language detection")
        print("  âœ“ Contamination filtering")
        print("  âœ“ Processing pipeline architecture")
        print("  âœ“ Configuration management")
        print("  âœ“ Context manager integration")
        print("  âœ“ Performance optimization")
        print("  âœ“ Error handling and edge cases")
        
        print("\nğŸš€ Processing System Status: FULLY FUNCTIONAL")
        print("ğŸ“ˆ Performance: Optimized (< 10ms per processor)")
        print("ğŸ”§ Maintainability: JSON-based configuration")
        print("ğŸ§© Modularity: Plugin-based architecture")
        print("=" * 60)


async def main():
    """Run the processing system tests."""
    tester = ProcessingSystemTester()
    
    print("Starting Aletheia Processing System Tests...")
    print("This validates the new generic processing architecture.")
    
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main()) 